{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73423984ecbf2895",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For data profiling and pycaret\n",
    "!pip install \"matplotlib>=3.2,<=3.7.3\"\n",
    "!pip install \"ydata-profiling>4.4,<4.5\" pycaret\n",
    "!pip install tensorflow sdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2c52b6448e4205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:48:35.013291239Z",
     "start_time": "2023-12-04T12:48:30.744510453Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 12:48:18.963196: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-04 12:48:19.175310: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 12:48:19.175365: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 12:48:19.176480: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 12:48:19.285731: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-04 12:48:19.287431: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 12:48:20.404279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff542f0c8303f91",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup\n",
    "conda create --name \"pia-tf\" python=3.10.9 ipython\n",
    "conda activate pia-tf\n",
    "conda install jupyter pip\n",
    "pip install pandas numpy tensorflow keras-tuner\n",
    "conda deactivate && python -m ipykernel install --user --name pia-tf\n",
    "nano ~/.local/share/jupyter/kernels/pia-tf/kernel.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef951ab940b36f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ideas\n",
    "\n",
    "If adversary does not work, predict -> predict_proba to get more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:48:34.788886071Z",
     "start_time": "2023-11-02T16:48:32.698448368Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from pia_functions import data_train_test, get_distributed_adult_sets, generate_shadow_model_outputs, train_gradient_boosting_shadow_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491152df6e7f325",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generate training data for shadow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0633c8de98074",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_shadow_models=200\n",
    "distributions=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adde3f38057445c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:24:40.911841937Z",
     "start_time": "2023-11-02T16:24:40.342020705Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, sensitive, sensitive_t = data_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60ac3040004ae21a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:41:10.508102179Z",
     "start_time": "2023-11-02T15:41:10.450313158Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.312424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.397083</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.801682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.421440</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.419976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.817372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0.534707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.794512</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.213765</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>0.780324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         0         1    2         3    4    5    6    7    8  \\\n",
       "0              0  0.312424  0.000000  0.0  0.094047  0.0  0.0  0.0  0.0  1.0   \n",
       "1              1  0.397083  0.004028  0.0  0.399298  0.0  0.0  0.0  0.0  1.0   \n",
       "2              2  0.801682  0.000000  0.0  0.499176  0.0  0.0  0.0  0.0  1.0   \n",
       "3              3  0.421440  0.003712  0.0  0.394823  0.0  0.0  0.0  0.0  0.0   \n",
       "4              4  0.419976  0.000000  0.0  0.392910  0.0  0.0  0.0  0.0  1.0   \n",
       "...          ...       ...       ...  ...       ...  ...  ...  ...  ...  ...   \n",
       "9995        9995  0.817372  0.000000  0.0  0.398106  0.0  0.0  0.0  0.0  1.0   \n",
       "9996        9996  0.534707  0.000000  0.0  0.393522  0.0  0.0  0.0  0.0  0.0   \n",
       "9997        9997  0.794512  0.160842  0.0  0.402341  0.0  0.0  0.0  0.0  1.0   \n",
       "9998        9998  0.213765  0.003364  0.0  0.397423  0.0  0.0  1.0  0.0  1.0   \n",
       "9999        9999  0.780324  0.000000  0.0  0.394290  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "      ...   69   70   71   72   73   74   75   76   77   78  \n",
       "0     ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "1     ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "2     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3     ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4     ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "9995  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "9996  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "9997  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "9998  ...  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "9999  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "\n",
       "[10000 rows x 80 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70300b02ce1dc6e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:44:44.115123136Z",
     "start_time": "2023-11-02T15:44:43.947862808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_input = pd.read_csv(\"data/syn_data.csv\", names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e584a017832f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distributed_datasets = get_distributed_adult_sets(distributions=distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d94488c6cda5c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate synthetic data for model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4966977f245991b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T13:45:47.063229923Z",
     "start_time": "2023-11-02T13:45:46.705563600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_size = 10000\n",
    "metadata = SingleTableMetadata()\n",
    "to_fit = pd.DataFrame(np.concatenate((X_train, X_test)), columns=[str(i) for i in range(79)])\n",
    "#to_fit = to_fit.astype({i: 'int' for i in range(4,79)})\n",
    "#to_fit[\"index\"] = to_fit.index\n",
    "#to_fit = to_fit.astype({\"index\": 'string'})\n",
    "metadata.detect_from_dataframe(data=to_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256f653a46f92733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T12:55:23.395722216Z",
     "start_time": "2023-11-02T12:55:23.380444040Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'METADATA_SPEC_VERSION': 'SINGLE_TABLE_V1',\n",
       " 'columns': {'0': {'sdtype': 'numerical'},\n",
       "  '1': {'sdtype': 'numerical'},\n",
       "  '2': {'sdtype': 'numerical'},\n",
       "  '3': {'sdtype': 'numerical'},\n",
       "  '4': {'sdtype': 'categorical'},\n",
       "  '5': {'sdtype': 'categorical'},\n",
       "  '6': {'sdtype': 'categorical'},\n",
       "  '7': {'sdtype': 'categorical'},\n",
       "  '8': {'sdtype': 'categorical'},\n",
       "  '9': {'sdtype': 'categorical'},\n",
       "  '10': {'sdtype': 'categorical'},\n",
       "  '11': {'sdtype': 'categorical'},\n",
       "  '12': {'sdtype': 'categorical'},\n",
       "  '13': {'sdtype': 'categorical'},\n",
       "  '14': {'sdtype': 'categorical'},\n",
       "  '15': {'sdtype': 'categorical'},\n",
       "  '16': {'sdtype': 'categorical'},\n",
       "  '17': {'sdtype': 'categorical'},\n",
       "  '18': {'sdtype': 'categorical'},\n",
       "  '19': {'sdtype': 'categorical'},\n",
       "  '20': {'sdtype': 'categorical'},\n",
       "  '21': {'sdtype': 'categorical'},\n",
       "  '22': {'sdtype': 'categorical'},\n",
       "  '23': {'sdtype': 'categorical'},\n",
       "  '24': {'sdtype': 'categorical'},\n",
       "  '25': {'sdtype': 'categorical'},\n",
       "  '26': {'sdtype': 'categorical'},\n",
       "  '27': {'sdtype': 'categorical'},\n",
       "  '28': {'sdtype': 'categorical'},\n",
       "  '29': {'sdtype': 'categorical'},\n",
       "  '30': {'sdtype': 'categorical'},\n",
       "  '31': {'sdtype': 'categorical'},\n",
       "  '32': {'sdtype': 'categorical'},\n",
       "  '33': {'sdtype': 'categorical'},\n",
       "  '34': {'sdtype': 'categorical'},\n",
       "  '35': {'sdtype': 'categorical'},\n",
       "  '36': {'sdtype': 'categorical'},\n",
       "  '37': {'sdtype': 'categorical'},\n",
       "  '38': {'sdtype': 'categorical'},\n",
       "  '39': {'sdtype': 'categorical'},\n",
       "  '40': {'sdtype': 'categorical'},\n",
       "  '41': {'sdtype': 'categorical'},\n",
       "  '42': {'sdtype': 'categorical'},\n",
       "  '43': {'sdtype': 'categorical'},\n",
       "  '44': {'sdtype': 'categorical'},\n",
       "  '45': {'sdtype': 'categorical'},\n",
       "  '46': {'sdtype': 'categorical'},\n",
       "  '47': {'sdtype': 'categorical'},\n",
       "  '48': {'sdtype': 'categorical'},\n",
       "  '49': {'sdtype': 'categorical'},\n",
       "  '50': {'sdtype': 'categorical'},\n",
       "  '51': {'sdtype': 'categorical'},\n",
       "  '52': {'sdtype': 'categorical'},\n",
       "  '53': {'sdtype': 'categorical'},\n",
       "  '54': {'sdtype': 'categorical'},\n",
       "  '55': {'sdtype': 'categorical'},\n",
       "  '56': {'sdtype': 'categorical'},\n",
       "  '57': {'sdtype': 'categorical'},\n",
       "  '58': {'sdtype': 'categorical'},\n",
       "  '59': {'sdtype': 'categorical'},\n",
       "  '60': {'sdtype': 'categorical'},\n",
       "  '61': {'sdtype': 'categorical'},\n",
       "  '62': {'sdtype': 'categorical'},\n",
       "  '63': {'sdtype': 'categorical'},\n",
       "  '64': {'sdtype': 'categorical'},\n",
       "  '65': {'sdtype': 'categorical'},\n",
       "  '66': {'sdtype': 'categorical'},\n",
       "  '67': {'sdtype': 'categorical'},\n",
       "  '68': {'sdtype': 'categorical'},\n",
       "  '69': {'sdtype': 'categorical'},\n",
       "  '70': {'sdtype': 'categorical'},\n",
       "  '71': {'sdtype': 'categorical'},\n",
       "  '72': {'sdtype': 'categorical'},\n",
       "  '73': {'sdtype': 'categorical'},\n",
       "  '74': {'sdtype': 'categorical'},\n",
       "  '75': {'sdtype': 'categorical'},\n",
       "  '76': {'sdtype': 'categorical'},\n",
       "  '77': {'sdtype': 'categorical'},\n",
       "  '78': {'sdtype': 'categorical'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f73cf065d62b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T14:58:12.472500848Z",
     "start_time": "2023-11-02T13:45:49.925861317Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/js/anaconda3/envs/adversarial-bb-training/lib/python3.10/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column '0'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/js/anaconda3/envs/adversarial-bb-training/lib/python3.10/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column '1'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/js/anaconda3/envs/adversarial-bb-training/lib/python3.10/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column '2'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/js/anaconda3/envs/adversarial-bb-training/lib/python3.10/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column '3'. Data will not be rounded.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "syn_model = CTGANSynthesizer(metadata)\n",
    "syn_model.fit(to_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54987eb0fe68a21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:21:04.789129304Z",
     "start_time": "2023-11-02T15:21:03.416962416Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled = syn_model.sample(num_rows=output_size)\n",
    "syn_model.save('syn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a9e498939ce4c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:44:33.840325056Z",
     "start_time": "2023-11-02T15:44:33.341592270Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled.to_csv(\"data/syn_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9851439390c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bca8b91daeae08fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:26:37.559252660Z",
     "start_time": "2023-11-02T16:26:12.762745018Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = train_gradient_boosting_shadow_model(X_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eddc9bcf8276f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:26:57.192105907Z",
     "start_time": "2023-11-02T16:26:57.091131035Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_input = pd.read_csv(\"data/syn_data.csv\", names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a29465417e19445d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:40:22.632354320Z",
     "start_time": "2023-11-02T16:40:22.535126646Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = gb.predict_proba(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf3a8ed59df205e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:41:12.142172466Z",
     "start_time": "2023-11-02T16:41:12.125214813Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99868971, 0.01143   , 0.01576805, ..., 0.96033791, 0.00722861,\n",
       "       0.0585728 ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bffb3c7283c77db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:28:31.500872863Z",
     "start_time": "2023-11-02T16:28:31.499984574Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    8676\n",
       "1.0    1325\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd819536f4e169",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Train shadow models and generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807403d039c8b5b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_shadow_outputs = []\n",
    "for ds in distributed_datasets:\n",
    "    outputs = generate_shadow_model_outputs(ds, X_test, n_shadow_models=n_shadow_models)\n",
    "    all_shadow_outputs.append(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a909c59c49960cd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save shadow model outputs to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b6fcb52d256ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adv_df = pd.DataFrame(np.array(np.concatenate((all_shadow_outputs))))\n",
    "adv_df[\"y\"] = np.concatenate(([np.repeat(d, n_shadow_models) for d in distributions]))\n",
    "adv_df.to_csv(\"data/shadow_model_outputs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f148b8fe9e7013",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Shadow model outputs as training data for adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccad5e8b03ad4d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:49:05.628851291Z",
     "start_time": "2023-12-04T12:48:51.065249751Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adv_df = pd.read_csv(\"data/shadow_model_outputs.csv\")\n",
    "adv_df = pd.read_csv(\"data/shadow_model_outputs_proba.csv\")\n",
    "adv_ddf_shuffled = adv_df.sample(frac=1, random_state=1).reset_index(drop=True).drop(columns=[\"Unnamed: 0\"])\n",
    "adv_y = adv_ddf_shuffled[\"y\"]\n",
    "adv_X = adv_ddf_shuffled.drop(columns=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b611ad15ca42d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:49:20.196768952Z",
     "start_time": "2023-12-04T12:49:05.629374488Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adv_df_test = pd.read_csv(\"data/shadow_model_outputs_proba_test_set.csv\")\n",
    "adv_ddf_shuffled_test = adv_df_test.sample(frac=1, random_state=1).reset_index(drop=True).drop(columns=[\"Unnamed: 0\"])\n",
    "adv_y_test = adv_ddf_shuffled_test[\"y\"]\n",
    "adv_X_test = adv_ddf_shuffled_test.drop(columns=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3613e1abec47249e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:15:51.357156638Z",
     "start_time": "2023-12-04T12:15:51.348836022Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '19992', '19993', '19994', '19995', '19996', '19997', '19998', '19999',\n",
       "       '20000', '20001'],\n",
       "      dtype='object', length=20002)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e1ee526589f4c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create adversary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26875e3f7ca757e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46c9cbdded7db22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T15:00:35.696786Z",
     "start_time": "2023-11-08T15:00:33.116627092Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_eigh' from 'sklearn.utils.fixes' (/home/jstock/anaconda3/envs/pia-tf/lib/python3.10/site-packages/sklearn/utils/fixes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m adv_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(adv_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m s \u001b[38;5;241m=\u001b[39m setup(adv_df, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/pycaret/classification/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     add_metric,\n\u001b[1;32m      3\u001b[0m     automl,\n\u001b[1;32m      4\u001b[0m     blend_models,\n\u001b[1;32m      5\u001b[0m     calibrate_model,\n\u001b[1;32m      6\u001b[0m     check_drift,\n\u001b[1;32m      7\u001b[0m     check_fairness,\n\u001b[1;32m      8\u001b[0m     compare_models,\n\u001b[1;32m      9\u001b[0m     convert_model,\n\u001b[1;32m     10\u001b[0m     create_api,\n\u001b[1;32m     11\u001b[0m     create_app,\n\u001b[1;32m     12\u001b[0m     create_docker,\n\u001b[1;32m     13\u001b[0m     create_model,\n\u001b[1;32m     14\u001b[0m     dashboard,\n\u001b[1;32m     15\u001b[0m     deploy_model,\n\u001b[1;32m     16\u001b[0m     ensemble_model,\n\u001b[1;32m     17\u001b[0m     evaluate_model,\n\u001b[1;32m     18\u001b[0m     finalize_model,\n\u001b[1;32m     19\u001b[0m     get_allowed_engines,\n\u001b[1;32m     20\u001b[0m     get_config,\n\u001b[1;32m     21\u001b[0m     get_current_experiment,\n\u001b[1;32m     22\u001b[0m     get_engine,\n\u001b[1;32m     23\u001b[0m     get_leaderboard,\n\u001b[1;32m     24\u001b[0m     get_logs,\n\u001b[1;32m     25\u001b[0m     get_metrics,\n\u001b[1;32m     26\u001b[0m     interpret_model,\n\u001b[1;32m     27\u001b[0m     load_experiment,\n\u001b[1;32m     28\u001b[0m     load_model,\n\u001b[1;32m     29\u001b[0m     models,\n\u001b[1;32m     30\u001b[0m     optimize_threshold,\n\u001b[1;32m     31\u001b[0m     plot_model,\n\u001b[1;32m     32\u001b[0m     predict_model,\n\u001b[1;32m     33\u001b[0m     pull,\n\u001b[1;32m     34\u001b[0m     remove_metric,\n\u001b[1;32m     35\u001b[0m     save_experiment,\n\u001b[1;32m     36\u001b[0m     save_model,\n\u001b[1;32m     37\u001b[0m     set_config,\n\u001b[1;32m     38\u001b[0m     set_current_experiment,\n\u001b[1;32m     39\u001b[0m     setup,\n\u001b[1;32m     40\u001b[0m     stack_models,\n\u001b[1;32m     41\u001b[0m     tune_model,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationExperiment\n\u001b[1;32m     45\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassificationExperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_drift\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/pycaret/classification/functional.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Memory\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationExperiment\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelBackend\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLogger\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/pycaret/classification/oop.py:29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_estimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     CustomProbabilityThresholdClassifier,\n\u001b[1;32m     26\u001b[0m     get_estimator_from_meta_estimator,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelBackend\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline \u001b[38;5;28;01mas\u001b[39;00m InternalPipeline\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocess\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Preprocessor\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpycaret_experiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnon_ts_supervised_experiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     _NonTSSupervisedExperiment,\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/pycaret/internal/pipeline.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m signature\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/imblearn/combine/_smote_enn.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/imblearn/over_sampling/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/imblearn/over_sampling/_smote/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVMSMOTE, BorderlineSMOTE\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVMSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/imblearn/over_sampling/_smote/cluster.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MiniBatchKMeans\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_distances\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/sklearn/cluster/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.cluster` module gathers popular unsupervised clustering\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03malgorithms.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_spectral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spectral_clustering, SpectralClustering\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mean_shift\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_shift, MeanShift, estimate_bandwidth, get_bin_seeds\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_affinity_propagation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m affinity_propagation, AffinityPropagation\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/sklearn/cluster/_spectral.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_kernels, KERNEL_PARAMS\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kneighbors_graph, NearestNeighbors\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spectral_embedding\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kmeans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m k_means\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcluster_qr\u001b[39m(vectors):\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/sklearn/manifold/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.manifold` module implements data embedding techniques.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_locally_linear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m locally_linear_embedding, LocallyLinearEmbedding\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isomap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Isomap\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MDS, smacof\n",
      "File \u001b[0;32m~/anaconda3/envs/pia-tf/lib/python3.10/site-packages/sklearn/manifold/_locally_linear.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_arpack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _init_arpack_v0\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, StrOptions\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _eigh\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stable_cumsum\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_eigh' from 'sklearn.utils.fixes' (/home/jstock/anaconda3/envs/pia-tf/lib/python3.10/site-packages/sklearn/utils/fixes.py)"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "s = setup(adv_df, target=\"y\", session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6826e165fc2870aa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T16:49:32.347176293Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import RegressionExperiment\n",
    "exp = RegressionExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c85b5dc284e7439",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T16:50:05.880228196Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.regression.oop.RegressionExperiment at 0x7fc0881bc4f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.setup(adv_df, target = 'y', session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b4643f397831",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T16:50:31.534970762Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>17:50:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Loading Dependencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Compiling Library</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    \n",
       "                                                                    \n",
       "Initiated  . . . . . . . . . . . . . . . . . .              17:50:31\n",
       "Status     . . . . . . . . . . . . . . . . . .  Loading Dependencies\n",
       "Estimator  . . . . . . . . . . . . . . . . . .     Compiling Library"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a29fc052b24739aa010193b11c9f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd898d04bc7d681",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trying different model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f321d38c0dbd2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:58:53.245867051Z",
     "start_time": "2023-12-04T12:58:53.185103051Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adversary = keras.Sequential()\n",
    "adversary.add(keras.Input(shape=(adv_X.shape[1],)))\n",
    "\n",
    "\n",
    "#adversary.add(keras.layers.Reshape((adv_X.shape[1],1)))\n",
    "#adversary.add(keras.layers.LSTM(6, activation='relu', return_sequences=False, return_state=False))\n",
    "\n",
    "#adversary.add(keras.layers.AveragePooling1D(\n",
    "#    #input_shape=(None,adv_X.shape[1],),\n",
    "#    pool_size=3, strides=1, padding=\"valid\", data_format=\"channels_last\"\n",
    "#))\n",
    "#adversary.add(keras.layers.MaxPooling1D(pool_size=2, strides=1, padding='valid'))\n",
    "#adversary.add(keras.layers.Reshape((adv_X.shape[1],)))\n",
    "\n",
    "#adversary.add(keras.layers.LayerNormalization(axis=1))\n",
    "#adversary.add(keras.layers.Dense(500))\n",
    "#adversary.add(keras.layers.Dense(64, activation='relu'))\n",
    "#adversary.add(keras.layers.Dropout(rate=0.1))\n",
    "adversary.add(keras.layers.Dense(40, activation='relu'))\n",
    "\n",
    "#adversary.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "adversary.add(keras.layers.Dropout(rate=0.05))\n",
    "#adversary.add(keras.layers.TimeDistributed(keras.layers.Dense(1)))\n",
    "#adversary.add(keras.layers.Dense(2, activation='relu'))\n",
    "#adversary.add(keras.layers.Flatten())\n",
    "adversary.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "adversary.add(keras.layers.Dense(1))\n",
    "\n",
    "#learning_rate=0.000005\n",
    "initial_learning_rate=0.000003\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "#learning_rate=lr_schedule\n",
    "#adversary.compile(optimizer=keras.optimizers.Adam(clipnorm=1.0), loss=keras.losses.MeanSquaredError(), metrics=keras.metrics.R2Score())\n",
    "\n",
    "adversary.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.MeanSquaredError(), metrics=keras.metrics.R2Score())\n",
    "\n",
    "#adversary.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76908bfc96a372bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:58:53.303313977Z",
     "start_time": "2023-12-04T12:58:53.287438398Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from keras.utils import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5be01fe81d2faf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:59:31.712668321Z",
     "start_time": "2023-12-04T12:58:53.401945566Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/190\n",
      "23/23 [==============================] - 1s 42ms/step - loss: 1.0975 - r2_score: -15.4618 - val_loss: 0.0719 - val_r2_score: -0.0788\n",
      "Epoch 2/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1564 - r2_score: -1.3457 - val_loss: 0.0665 - val_r2_score: 0.0020\n",
      "Epoch 3/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0862 - r2_score: -0.2935 - val_loss: 0.0739 - val_r2_score: -0.1084\n",
      "Epoch 4/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0463 - r2_score: 0.3052 - val_loss: 0.0639 - val_r2_score: 0.0410\n",
      "Epoch 5/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0280 - r2_score: 0.5804 - val_loss: 0.0662 - val_r2_score: 0.0067\n",
      "Epoch 6/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0196 - r2_score: 0.7066 - val_loss: 0.0637 - val_r2_score: 0.0451\n",
      "Epoch 7/190\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0121 - r2_score: 0.8189 - val_loss: 0.0630 - val_r2_score: 0.0557\n",
      "Epoch 8/190\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0080 - r2_score: 0.8803 - val_loss: 0.0623 - val_r2_score: 0.0656\n",
      "Epoch 9/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0111 - r2_score: 0.8340 - val_loss: 0.0609 - val_r2_score: 0.0860\n",
      "Epoch 10/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0067 - r2_score: 0.8989 - val_loss: 0.0607 - val_r2_score: 0.0891\n",
      "Epoch 11/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0056 - r2_score: 0.9156 - val_loss: 0.0607 - val_r2_score: 0.0890\n",
      "Epoch 12/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0081 - r2_score: 0.8781 - val_loss: 0.0603 - val_r2_score: 0.0953\n",
      "Epoch 13/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0055 - r2_score: 0.9176 - val_loss: 0.0590 - val_r2_score: 0.1154\n",
      "Epoch 14/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0039 - r2_score: 0.9412 - val_loss: 0.0587 - val_r2_score: 0.1189\n",
      "Epoch 15/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0043 - r2_score: 0.9361 - val_loss: 0.0584 - val_r2_score: 0.1240\n",
      "Epoch 16/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0045 - r2_score: 0.9320 - val_loss: 0.0589 - val_r2_score: 0.1164\n",
      "Epoch 17/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0048 - r2_score: 0.9283 - val_loss: 0.0584 - val_r2_score: 0.1241\n",
      "Epoch 18/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0043 - r2_score: 0.9361 - val_loss: 0.0578 - val_r2_score: 0.1335\n",
      "Epoch 19/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0049 - r2_score: 0.9264 - val_loss: 0.0591 - val_r2_score: 0.1136\n",
      "Epoch 20/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0041 - r2_score: 0.9388 - val_loss: 0.0577 - val_r2_score: 0.1348\n",
      "Epoch 21/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0044 - r2_score: 0.9347 - val_loss: 0.0577 - val_r2_score: 0.1347\n",
      "Epoch 22/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0038 - r2_score: 0.9427 - val_loss: 0.0568 - val_r2_score: 0.1484\n",
      "Epoch 23/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0033 - r2_score: 0.9501 - val_loss: 0.0575 - val_r2_score: 0.1371\n",
      "Epoch 24/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0033 - r2_score: 0.9499 - val_loss: 0.0569 - val_r2_score: 0.1460\n",
      "Epoch 25/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0028 - r2_score: 0.9586 - val_loss: 0.0568 - val_r2_score: 0.1481\n",
      "Epoch 26/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0027 - r2_score: 0.9599 - val_loss: 0.0574 - val_r2_score: 0.1383\n",
      "Epoch 27/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0032 - r2_score: 0.9526 - val_loss: 0.0577 - val_r2_score: 0.1352\n",
      "Epoch 28/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0039 - r2_score: 0.9416 - val_loss: 0.0570 - val_r2_score: 0.1448\n",
      "Epoch 29/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0034 - r2_score: 0.9486 - val_loss: 0.0566 - val_r2_score: 0.1512\n",
      "Epoch 30/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0036 - r2_score: 0.9461 - val_loss: 0.0563 - val_r2_score: 0.1556\n",
      "Epoch 31/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0030 - r2_score: 0.9546 - val_loss: 0.0561 - val_r2_score: 0.1579\n",
      "Epoch 32/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0031 - r2_score: 0.9536 - val_loss: 0.0560 - val_r2_score: 0.1604\n",
      "Epoch 33/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0026 - r2_score: 0.9604 - val_loss: 0.0565 - val_r2_score: 0.1519\n",
      "Epoch 34/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0028 - r2_score: 0.9576 - val_loss: 0.0556 - val_r2_score: 0.1655\n",
      "Epoch 35/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0027 - r2_score: 0.9602 - val_loss: 0.0559 - val_r2_score: 0.1608\n",
      "Epoch 36/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0029 - r2_score: 0.9558 - val_loss: 0.0560 - val_r2_score: 0.1594\n",
      "Epoch 37/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0031 - r2_score: 0.9540 - val_loss: 0.0559 - val_r2_score: 0.1613\n",
      "Epoch 38/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0021 - r2_score: 0.9684 - val_loss: 0.0568 - val_r2_score: 0.1486\n",
      "Epoch 39/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0033 - r2_score: 0.9509 - val_loss: 0.0570 - val_r2_score: 0.1444\n",
      "Epoch 40/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0017 - r2_score: 0.9747 - val_loss: 0.0565 - val_r2_score: 0.1521\n",
      "Epoch 41/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0020 - r2_score: 0.9699 - val_loss: 0.0557 - val_r2_score: 0.1644\n",
      "Epoch 42/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0016 - r2_score: 0.9757 - val_loss: 0.0564 - val_r2_score: 0.1542\n",
      "Epoch 43/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0021 - r2_score: 0.9691 - val_loss: 0.0559 - val_r2_score: 0.1618\n",
      "Epoch 44/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0017 - r2_score: 0.9752 - val_loss: 0.0559 - val_r2_score: 0.1619\n",
      "Epoch 45/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0023 - r2_score: 0.9660 - val_loss: 0.0556 - val_r2_score: 0.1653\n",
      "Epoch 46/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0025 - r2_score: 0.9632 - val_loss: 0.0551 - val_r2_score: 0.1729\n",
      "Epoch 47/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0015 - r2_score: 0.9771 - val_loss: 0.0552 - val_r2_score: 0.1724\n",
      "Epoch 48/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0017 - r2_score: 0.9743 - val_loss: 0.0551 - val_r2_score: 0.1731\n",
      "Epoch 49/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0021 - r2_score: 0.9685 - val_loss: 0.0548 - val_r2_score: 0.1785\n",
      "Epoch 50/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0020 - r2_score: 0.9703 - val_loss: 0.0551 - val_r2_score: 0.1737\n",
      "Epoch 51/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0018 - r2_score: 0.9731 - val_loss: 0.0547 - val_r2_score: 0.1798\n",
      "Epoch 52/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0016 - r2_score: 0.9759 - val_loss: 0.0549 - val_r2_score: 0.1771\n",
      "Epoch 53/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0014 - r2_score: 0.9790 - val_loss: 0.0546 - val_r2_score: 0.1804\n",
      "Epoch 54/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9812 - val_loss: 0.0549 - val_r2_score: 0.1768\n",
      "Epoch 55/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0012 - r2_score: 0.9818 - val_loss: 0.0546 - val_r2_score: 0.1803\n",
      "Epoch 56/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0019 - r2_score: 0.9717 - val_loss: 0.0545 - val_r2_score: 0.1827\n",
      "Epoch 57/190\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0014 - r2_score: 0.9797 - val_loss: 0.0544 - val_r2_score: 0.1842\n",
      "Epoch 58/190\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0026 - r2_score: 0.9607 - val_loss: 0.0547 - val_r2_score: 0.1792\n",
      "Epoch 59/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9832 - val_loss: 0.0546 - val_r2_score: 0.1812\n",
      "Epoch 60/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0022 - r2_score: 0.9665 - val_loss: 0.0543 - val_r2_score: 0.1848\n",
      "Epoch 61/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9807 - val_loss: 0.0541 - val_r2_score: 0.1882\n",
      "Epoch 62/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0017 - r2_score: 0.9749 - val_loss: 0.0542 - val_r2_score: 0.1867\n",
      "Epoch 63/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0014 - r2_score: 0.9784 - val_loss: 0.0543 - val_r2_score: 0.1851\n",
      "Epoch 64/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0013 - r2_score: 0.9799 - val_loss: 0.0542 - val_r2_score: 0.1865\n",
      "Epoch 65/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0021 - r2_score: 0.9686 - val_loss: 0.0540 - val_r2_score: 0.1899\n",
      "Epoch 66/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9839 - val_loss: 0.0540 - val_r2_score: 0.1894\n",
      "Epoch 67/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0015 - r2_score: 0.9777 - val_loss: 0.0540 - val_r2_score: 0.1903\n",
      "Epoch 68/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0020 - r2_score: 0.9704 - val_loss: 0.0541 - val_r2_score: 0.1878\n",
      "Epoch 69/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.4754e-04 - r2_score: 0.9873 - val_loss: 0.0541 - val_r2_score: 0.1878\n",
      "Epoch 70/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9798 - val_loss: 0.0541 - val_r2_score: 0.1891\n",
      "Epoch 71/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0022 - r2_score: 0.9668 - val_loss: 0.0540 - val_r2_score: 0.1894\n",
      "Epoch 72/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0012 - r2_score: 0.9814 - val_loss: 0.0542 - val_r2_score: 0.1876\n",
      "Epoch 73/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0018 - r2_score: 0.9723 - val_loss: 0.0539 - val_r2_score: 0.1911\n",
      "Epoch 74/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9812 - val_loss: 0.0541 - val_r2_score: 0.1880\n",
      "Epoch 75/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0011 - r2_score: 0.9836 - val_loss: 0.0540 - val_r2_score: 0.1905\n",
      "Epoch 76/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0015 - r2_score: 0.9778 - val_loss: 0.0541 - val_r2_score: 0.1887\n",
      "Epoch 77/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0020 - r2_score: 0.9698 - val_loss: 0.0544 - val_r2_score: 0.1840\n",
      "Epoch 78/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.5453e-04 - r2_score: 0.9857 - val_loss: 0.0540 - val_r2_score: 0.1906\n",
      "Epoch 79/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.7495e-04 - r2_score: 0.9869 - val_loss: 0.0537 - val_r2_score: 0.1944\n",
      "Epoch 80/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9803 - val_loss: 0.0538 - val_r2_score: 0.1929\n",
      "Epoch 81/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.9514e-04 - r2_score: 0.9881 - val_loss: 0.0537 - val_r2_score: 0.1941\n",
      "Epoch 82/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.1742e-04 - r2_score: 0.9892 - val_loss: 0.0538 - val_r2_score: 0.1933\n",
      "Epoch 83/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0016 - r2_score: 0.9760 - val_loss: 0.0538 - val_r2_score: 0.1934\n",
      "Epoch 84/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.9776e-04 - r2_score: 0.9895 - val_loss: 0.0539 - val_r2_score: 0.1917\n",
      "Epoch 85/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9833 - val_loss: 0.0538 - val_r2_score: 0.1924\n",
      "Epoch 86/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0012 - r2_score: 0.9819 - val_loss: 0.0537 - val_r2_score: 0.1944\n",
      "Epoch 87/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9808 - val_loss: 0.0537 - val_r2_score: 0.1943\n",
      "Epoch 88/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.4591e-04 - r2_score: 0.9888 - val_loss: 0.0540 - val_r2_score: 0.1906\n",
      "Epoch 89/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.0152e-04 - r2_score: 0.9880 - val_loss: 0.0538 - val_r2_score: 0.1930\n",
      "Epoch 90/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0014 - r2_score: 0.9785 - val_loss: 0.0540 - val_r2_score: 0.1898\n",
      "Epoch 91/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.4150e-04 - r2_score: 0.9874 - val_loss: 0.0538 - val_r2_score: 0.1924\n",
      "Epoch 92/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.2289e-04 - r2_score: 0.9877 - val_loss: 0.0540 - val_r2_score: 0.1907\n",
      "Epoch 93/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9807 - val_loss: 0.0539 - val_r2_score: 0.1922\n",
      "Epoch 94/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.3776e-04 - r2_score: 0.9874 - val_loss: 0.0540 - val_r2_score: 0.1901\n",
      "Epoch 95/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0019 - r2_score: 0.9720 - val_loss: 0.0537 - val_r2_score: 0.1940\n",
      "Epoch 96/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.4763e-04 - r2_score: 0.9903 - val_loss: 0.0539 - val_r2_score: 0.1912\n",
      "Epoch 97/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.5917e-04 - r2_score: 0.9901 - val_loss: 0.0535 - val_r2_score: 0.1969\n",
      "Epoch 98/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.4636e-04 - r2_score: 0.9873 - val_loss: 0.0538 - val_r2_score: 0.1934\n",
      "Epoch 99/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0012 - r2_score: 0.9821 - val_loss: 0.0537 - val_r2_score: 0.1945\n",
      "Epoch 100/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.7415e-04 - r2_score: 0.9854 - val_loss: 0.0536 - val_r2_score: 0.1957\n",
      "Epoch 101/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.6295e-04 - r2_score: 0.9856 - val_loss: 0.0538 - val_r2_score: 0.1930\n",
      "Epoch 102/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.5762e-04 - r2_score: 0.9871 - val_loss: 0.0537 - val_r2_score: 0.1951\n",
      "Epoch 103/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 8.4289e-04 - r2_score: 0.9874 - val_loss: 0.0537 - val_r2_score: 0.1940\n",
      "Epoch 104/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0014 - r2_score: 0.9797 - val_loss: 0.0536 - val_r2_score: 0.1957\n",
      "Epoch 105/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.7710e-04 - r2_score: 0.9883 - val_loss: 0.0538 - val_r2_score: 0.1925\n",
      "Epoch 106/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0012 - r2_score: 0.9813 - val_loss: 0.0537 - val_r2_score: 0.1940\n",
      "Epoch 107/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0014 - r2_score: 0.9796 - val_loss: 0.0536 - val_r2_score: 0.1967\n",
      "Epoch 108/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0010 - r2_score: 0.9846 - val_loss: 0.0542 - val_r2_score: 0.1864\n",
      "Epoch 109/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.0788e-04 - r2_score: 0.9894 - val_loss: 0.0537 - val_r2_score: 0.1943\n",
      "Epoch 110/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.6510e-04 - r2_score: 0.9900 - val_loss: 0.0536 - val_r2_score: 0.1961\n",
      "Epoch 111/190\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 3.5492e-04 - r2_score: 0.9947 - val_loss: 0.0535 - val_r2_score: 0.1969\n",
      "Epoch 112/190\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 7.1221e-04 - r2_score: 0.9893 - val_loss: 0.0536 - val_r2_score: 0.1967\n",
      "Epoch 113/190\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.7606e-04 - r2_score: 0.9959 - val_loss: 0.0535 - val_r2_score: 0.1978\n",
      "Epoch 114/190\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 7.3117e-04 - r2_score: 0.9890 - val_loss: 0.0536 - val_r2_score: 0.1961\n",
      "Epoch 115/190\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 5.3932e-04 - r2_score: 0.9919 - val_loss: 0.0535 - val_r2_score: 0.1970\n",
      "Epoch 116/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.0450e-04 - r2_score: 0.9894 - val_loss: 0.0536 - val_r2_score: 0.1962\n",
      "Epoch 117/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 4.0718e-04 - r2_score: 0.9939 - val_loss: 0.0535 - val_r2_score: 0.1969\n",
      "Epoch 118/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0012 - r2_score: 0.9822 - val_loss: 0.0537 - val_r2_score: 0.1945\n",
      "Epoch 119/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.5914e-04 - r2_score: 0.9901 - val_loss: 0.0537 - val_r2_score: 0.1948\n",
      "Epoch 120/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0017 - r2_score: 0.9751 - val_loss: 0.0535 - val_r2_score: 0.1980\n",
      "Epoch 121/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9841 - val_loss: 0.0536 - val_r2_score: 0.1958\n",
      "Epoch 122/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.7935e-04 - r2_score: 0.9898 - val_loss: 0.0536 - val_r2_score: 0.1965\n",
      "Epoch 123/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0014 - r2_score: 0.9793 - val_loss: 0.0536 - val_r2_score: 0.1956\n",
      "Epoch 124/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 7.2747e-04 - r2_score: 0.9891 - val_loss: 0.0535 - val_r2_score: 0.1971\n",
      "Epoch 125/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.5798e-04 - r2_score: 0.9901 - val_loss: 0.0535 - val_r2_score: 0.1980\n",
      "Epoch 126/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0015 - r2_score: 0.9775 - val_loss: 0.0535 - val_r2_score: 0.1970\n",
      "Epoch 127/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.9587e-04 - r2_score: 0.9866 - val_loss: 0.0537 - val_r2_score: 0.1948\n",
      "Epoch 128/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0015 - r2_score: 0.9772 - val_loss: 0.0537 - val_r2_score: 0.1940\n",
      "Epoch 129/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.1828e-04 - r2_score: 0.9862 - val_loss: 0.0538 - val_r2_score: 0.1931\n",
      "Epoch 130/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.7745e-04 - r2_score: 0.9883 - val_loss: 0.0535 - val_r2_score: 0.1972\n",
      "Epoch 131/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9807 - val_loss: 0.0535 - val_r2_score: 0.1970\n",
      "Epoch 132/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.5604e-04 - r2_score: 0.9872 - val_loss: 0.0534 - val_r2_score: 0.1994\n",
      "Epoch 133/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9842 - val_loss: 0.0539 - val_r2_score: 0.1920\n",
      "Epoch 134/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.5085e-04 - r2_score: 0.9857 - val_loss: 0.0539 - val_r2_score: 0.1913\n",
      "Epoch 135/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.6211e-04 - r2_score: 0.9901 - val_loss: 0.0537 - val_r2_score: 0.1949\n",
      "Epoch 136/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0014 - r2_score: 0.9786 - val_loss: 0.0540 - val_r2_score: 0.1899\n",
      "Epoch 137/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0015 - r2_score: 0.9773 - val_loss: 0.0540 - val_r2_score: 0.1907\n",
      "Epoch 138/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0014 - r2_score: 0.9796 - val_loss: 0.0535 - val_r2_score: 0.1982\n",
      "Epoch 139/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.6192e-04 - r2_score: 0.9871 - val_loss: 0.0537 - val_r2_score: 0.1951\n",
      "Epoch 140/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.1216e-04 - r2_score: 0.9908 - val_loss: 0.0536 - val_r2_score: 0.1953\n",
      "Epoch 141/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 3.5917e-04 - r2_score: 0.9946 - val_loss: 0.0537 - val_r2_score: 0.1947\n",
      "Epoch 142/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.1293e-04 - r2_score: 0.9863 - val_loss: 0.0535 - val_r2_score: 0.1975\n",
      "Epoch 143/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 6.3793e-04 - r2_score: 0.9904 - val_loss: 0.0535 - val_r2_score: 0.1976\n",
      "Epoch 144/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.2163e-04 - r2_score: 0.9877 - val_loss: 0.0537 - val_r2_score: 0.1941\n",
      "Epoch 145/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.0797e-04 - r2_score: 0.9894 - val_loss: 0.0534 - val_r2_score: 0.1989\n",
      "Epoch 146/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 8.9952e-04 - r2_score: 0.9865 - val_loss: 0.0539 - val_r2_score: 0.1922\n",
      "Epoch 147/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0010 - r2_score: 0.9844 - val_loss: 0.0536 - val_r2_score: 0.1964\n",
      "Epoch 148/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 3.4339e-04 - r2_score: 0.9948 - val_loss: 0.0534 - val_r2_score: 0.1997\n",
      "Epoch 149/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 6.0590e-04 - r2_score: 0.9909 - val_loss: 0.0538 - val_r2_score: 0.1927\n",
      "Epoch 150/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 4.1879e-04 - r2_score: 0.9937 - val_loss: 0.0534 - val_r2_score: 0.1992\n",
      "Epoch 151/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.7062e-04 - r2_score: 0.9959 - val_loss: 0.0534 - val_r2_score: 0.1990\n",
      "Epoch 152/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 5.2298e-04 - r2_score: 0.9922 - val_loss: 0.0535 - val_r2_score: 0.1975\n",
      "Epoch 153/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.2706e-04 - r2_score: 0.9891 - val_loss: 0.0533 - val_r2_score: 0.2002\n",
      "Epoch 154/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0016 - r2_score: 0.9753 - val_loss: 0.0541 - val_r2_score: 0.1887\n",
      "Epoch 155/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0011 - r2_score: 0.9828 - val_loss: 0.0537 - val_r2_score: 0.1940\n",
      "Epoch 156/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0010 - r2_score: 0.9844 - val_loss: 0.0532 - val_r2_score: 0.2016\n",
      "Epoch 157/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9838 - val_loss: 0.0534 - val_r2_score: 0.1994\n",
      "Epoch 158/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9841 - val_loss: 0.0536 - val_r2_score: 0.1965\n",
      "Epoch 159/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0013 - r2_score: 0.9810 - val_loss: 0.0536 - val_r2_score: 0.1967\n",
      "Epoch 160/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.0838e-04 - r2_score: 0.9864 - val_loss: 0.0540 - val_r2_score: 0.1895\n",
      "Epoch 161/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.8492e-04 - r2_score: 0.9957 - val_loss: 0.0532 - val_r2_score: 0.2016\n",
      "Epoch 162/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 6.7102e-04 - r2_score: 0.9899 - val_loss: 0.0534 - val_r2_score: 0.1984\n",
      "Epoch 163/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 6.7153e-04 - r2_score: 0.9899 - val_loss: 0.0534 - val_r2_score: 0.1985\n",
      "Epoch 164/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0012 - r2_score: 0.9815 - val_loss: 0.0537 - val_r2_score: 0.1951\n",
      "Epoch 165/190\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 6.5663e-04 - r2_score: 0.9902 - val_loss: 0.0533 - val_r2_score: 0.2003\n",
      "Epoch 166/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.6714e-04 - r2_score: 0.9885 - val_loss: 0.0532 - val_r2_score: 0.2018\n",
      "Epoch 167/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.2746e-04 - r2_score: 0.9891 - val_loss: 0.0534 - val_r2_score: 0.1994\n",
      "Epoch 168/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 4.8215e-04 - r2_score: 0.9928 - val_loss: 0.0532 - val_r2_score: 0.2019\n",
      "Epoch 169/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.8429e-04 - r2_score: 0.9957 - val_loss: 0.0532 - val_r2_score: 0.2019\n",
      "Epoch 170/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.6543e-04 - r2_score: 0.9900 - val_loss: 0.0532 - val_r2_score: 0.2023\n",
      "Epoch 171/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.2042e-04 - r2_score: 0.9862 - val_loss: 0.0531 - val_r2_score: 0.2030\n",
      "Epoch 172/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 5.7490e-04 - r2_score: 0.9914 - val_loss: 0.0533 - val_r2_score: 0.2010\n",
      "Epoch 173/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 5.8612e-04 - r2_score: 0.9912 - val_loss: 0.0532 - val_r2_score: 0.2016\n",
      "Epoch 174/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.9054e-04 - r2_score: 0.9851 - val_loss: 0.0537 - val_r2_score: 0.1945\n",
      "Epoch 175/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.6178e-04 - r2_score: 0.9901 - val_loss: 0.0532 - val_r2_score: 0.2016\n",
      "Epoch 176/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0011 - r2_score: 0.9839 - val_loss: 0.0533 - val_r2_score: 0.2004\n",
      "Epoch 177/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 3.4209e-04 - r2_score: 0.9949 - val_loss: 0.0533 - val_r2_score: 0.2002\n",
      "Epoch 178/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 5.8032e-04 - r2_score: 0.9913 - val_loss: 0.0531 - val_r2_score: 0.2028\n",
      "Epoch 179/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 5.7858e-04 - r2_score: 0.9913 - val_loss: 0.0539 - val_r2_score: 0.1910\n",
      "Epoch 180/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 5.7466e-04 - r2_score: 0.9914 - val_loss: 0.0536 - val_r2_score: 0.1965\n",
      "Epoch 181/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.5227e-04 - r2_score: 0.9857 - val_loss: 0.0540 - val_r2_score: 0.1906\n",
      "Epoch 182/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 9.2673e-04 - r2_score: 0.9861 - val_loss: 0.0523 - val_r2_score: 0.2156\n",
      "Epoch 183/190\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 8.1746e-04 - r2_score: 0.9877 - val_loss: 0.0534 - val_r2_score: 0.1995\n",
      "Epoch 184/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 7.7812e-04 - r2_score: 0.9883 - val_loss: 0.0533 - val_r2_score: 0.1999\n",
      "Epoch 185/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.4795e-04 - r2_score: 0.9963 - val_loss: 0.0530 - val_r2_score: 0.2043\n",
      "Epoch 186/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 5.0944e-04 - r2_score: 0.9924 - val_loss: 0.0529 - val_r2_score: 0.2059\n",
      "Epoch 187/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 6.8208e-04 - r2_score: 0.9898 - val_loss: 0.0530 - val_r2_score: 0.2053\n",
      "Epoch 188/190\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.3828e-04 - r2_score: 0.9979 - val_loss: 0.0530 - val_r2_score: 0.2050\n",
      "Epoch 189/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.9356e-04 - r2_score: 0.9956 - val_loss: 0.0532 - val_r2_score: 0.2024\n",
      "Epoch 190/190\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 4.2967e-04 - r2_score: 0.9936 - val_loss: 0.0530 - val_r2_score: 0.2043\n"
     ]
    }
   ],
   "source": [
    "history = adversary.fit(adv_X, adv_y, batch_size=80, epochs=190, validation_data=(adv_X_test, adv_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68ac14eebed1f3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T12:59:31.888907528Z",
     "start_time": "2023-12-04T12:59:31.712402092Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['r2_score'][2:])\n",
    "plt.plot(history.history['val_r2_score'][2:])\n",
    "plt.title('r_2 score')\n",
    "plt.ylabel('r_2 score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c071700f72f8529b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T13:00:10.436740657Z",
     "start_time": "2023-12-04T13:00:10.394954634Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.8\n",
       "1       0.3\n",
       "2       0.4\n",
       "3       0.7\n",
       "4       0.5\n",
       "       ... \n",
       "1795    0.5\n",
       "1796    0.9\n",
       "1797    0.6\n",
       "1798    0.2\n",
       "1799    0.6\n",
       "Name: y, Length: 1800, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea68fad4f4a365",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# New adversary: classification instead of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29fdf8159c2afe4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T13:00:26.432847377Z",
     "start_time": "2023-12-04T13:00:26.410986922Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adv_y_classification = np.array(adv_y*10-1, dtype=np.dtype(\"int\"))\n",
    "adv_y_test_classification = np.array(adv_y_test*10-1, dtype=np.dtype(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84a65b3d1b061a49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T13:35:26.665920066Z",
     "start_time": "2023-12-04T13:00:29.729598218Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1761111111111111"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline (classification)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(adv_X, adv_y_classification)\n",
    "gb.score(adv_X_test, adv_y_test_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edd92cc0b3bc0772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T13:36:55.878129737Z",
     "start_time": "2023-12-04T13:36:55.835608086Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jstock/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "adv_y_one_hot = enc.fit_transform(pd.array(adv_y_classification).reshape(-1, 1))\n",
    "adv_y_test_one_hot = enc.transform(pd.array(adv_y_test_classification).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ad50f56128a170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T13:49:13.248262871Z",
     "start_time": "2023-12-04T13:49:13.211977247Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classification\n",
    "adversary = keras.Sequential()\n",
    "adversary.add(keras.Input(shape=(adv_X.shape[1],)))\n",
    "\n",
    "#adversary.add(keras.layers.Reshape((adv_X.shape[1],1)))\n",
    "#adversary.add(keras.layers.LSTM(4, activation='relu', return_sequences=False, return_state=False))\n",
    "\n",
    "#adversary.add(keras.layers.AveragePooling1D(\n",
    "#    #input_shape=(None,adv_X.shape[1],),\n",
    "#    pool_size=3, strides=1, padding=\"valid\", data_format=\"channels_last\"\n",
    "#))\n",
    "#adversary.add(keras.layers.MaxPooling1D(pool_size=2, strides=1, padding='valid'))\n",
    "#adversary.add(keras.layers.Reshape((adv_X.shape[1],)))\n",
    "\n",
    "#adversary.add(keras.layers.LayerNormalization(axis=1))\n",
    "#adversary.add(keras.layers.Dense(500))\n",
    "#adversary.add(keras.layers.Dense(16, activation='relu'))\n",
    "#adversary.add(keras.layers.Dropout(rate=0.1))\n",
    "#adversary.add(keras.layers.TimeDistributed(keras.layers.Dense(1)))\n",
    "#adversary.add(keras.layers.Dense(2, activation='relu'))\n",
    "#adversary.add(keras.layers.Flatten())\n",
    "\n",
    "#adversary.add(keras.layers.Dense(32, activation=\"relu\"))\n",
    "adversary.add(keras.layers.Dense(40, activation='relu'))\n",
    "\n",
    "#adversary.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "adversary.add(keras.layers.Dropout(rate=0.05))\n",
    "#adversary.add(keras.layers.TimeDistributed(keras.layers.Dense(1)))\n",
    "#adversary.add(keras.layers.Dense(2, activation='relu'))\n",
    "#adversary.add(keras.layers.Flatten())\n",
    "adversary.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "adversary.add(keras.layers.Dense(9, activation=\"softmax\"))\n",
    "\n",
    "#learning_rate=0.000005\n",
    "initial_learning_rate=0.000003\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "#learning_rate=lr_schedule\n",
    "adversary.compile(optimizer=\"adam\", loss=keras.losses.CategoricalCrossentropy(from_logits=False), metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7075565f12356aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T13:49:52.056803922Z",
     "start_time": "2023-12-04T13:49:14.026203755Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 3.2470 - accuracy: 0.1311 - val_loss: 2.2045 - val_accuracy: 0.1111\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.1712 - accuracy: 0.1433 - val_loss: 2.1968 - val_accuracy: 0.0967\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.1459 - accuracy: 0.1583 - val_loss: 2.1982 - val_accuracy: 0.1111\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 2.1116 - accuracy: 0.1961 - val_loss: 2.1931 - val_accuracy: 0.1111\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.0793 - accuracy: 0.2139 - val_loss: 2.2136 - val_accuracy: 0.1111\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.0442 - accuracy: 0.2100 - val_loss: 2.1934 - val_accuracy: 0.1111\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.0233 - accuracy: 0.1933 - val_loss: 2.1929 - val_accuracy: 0.1111\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.9998 - accuracy: 0.2056 - val_loss: 2.2216 - val_accuracy: 0.1111\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9575 - accuracy: 0.2239 - val_loss: 2.1936 - val_accuracy: 0.1111\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9313 - accuracy: 0.2194 - val_loss: 2.2161 - val_accuracy: 0.1111\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9125 - accuracy: 0.2167 - val_loss: 2.2204 - val_accuracy: 0.1111\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8962 - accuracy: 0.2150 - val_loss: 2.2086 - val_accuracy: 0.1056\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8792 - accuracy: 0.2239 - val_loss: 2.2419 - val_accuracy: 0.1111\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8634 - accuracy: 0.2222 - val_loss: 2.2140 - val_accuracy: 0.0550\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8506 - accuracy: 0.2233 - val_loss: 2.2471 - val_accuracy: 0.0861\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8324 - accuracy: 0.2294 - val_loss: 2.2452 - val_accuracy: 0.0506\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8221 - accuracy: 0.2278 - val_loss: 2.2590 - val_accuracy: 0.0222\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8132 - accuracy: 0.2383 - val_loss: 2.2214 - val_accuracy: 0.0017\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8040 - accuracy: 0.2511 - val_loss: 2.3194 - val_accuracy: 0.0278\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.7895 - accuracy: 0.2400 - val_loss: 2.2550 - val_accuracy: 0.0922\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7843 - accuracy: 0.2428 - val_loss: 2.1685 - val_accuracy: 0.1317\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7901 - accuracy: 0.2561 - val_loss: 2.3184 - val_accuracy: 0.0739\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7624 - accuracy: 0.2622 - val_loss: 2.1822 - val_accuracy: 0.1656\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.7526 - accuracy: 0.2594 - val_loss: 2.3068 - val_accuracy: 0.1111\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7331 - accuracy: 0.2694 - val_loss: 2.2971 - val_accuracy: 0.1522\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.7236 - accuracy: 0.2783 - val_loss: 2.3811 - val_accuracy: 0.1111\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7137 - accuracy: 0.2872 - val_loss: 2.3305 - val_accuracy: 0.1128\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.7128 - accuracy: 0.2744 - val_loss: 2.2309 - val_accuracy: 0.1111\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7263 - accuracy: 0.2856 - val_loss: 2.1985 - val_accuracy: 0.1739\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7211 - accuracy: 0.2811 - val_loss: 2.1764 - val_accuracy: 0.1400\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6941 - accuracy: 0.2861 - val_loss: 2.3498 - val_accuracy: 0.1122\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6843 - accuracy: 0.2789 - val_loss: 2.2615 - val_accuracy: 0.1111\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6865 - accuracy: 0.3028 - val_loss: 2.2570 - val_accuracy: 0.1111\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.6724 - accuracy: 0.2994 - val_loss: 2.4244 - val_accuracy: 0.2211\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6560 - accuracy: 0.2761 - val_loss: 2.3128 - val_accuracy: 0.1106\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6924 - accuracy: 0.2867 - val_loss: 2.2125 - val_accuracy: 0.1817\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6887 - accuracy: 0.2872 - val_loss: 2.2176 - val_accuracy: 0.1428\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6767 - accuracy: 0.2817 - val_loss: 2.1815 - val_accuracy: 0.2200\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6417 - accuracy: 0.2867 - val_loss: 2.2944 - val_accuracy: 0.0422\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6325 - accuracy: 0.3006 - val_loss: 2.3117 - val_accuracy: 0.0017\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6078 - accuracy: 0.3328 - val_loss: 2.4752 - val_accuracy: 0.0083\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.6051 - accuracy: 0.3383 - val_loss: 2.4664 - val_accuracy: 0.0933\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6058 - accuracy: 0.3339 - val_loss: 2.2592 - val_accuracy: 0.1133\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6542 - accuracy: 0.2783 - val_loss: 2.5102 - val_accuracy: 0.1100\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.7109 - accuracy: 0.2533 - val_loss: 2.2114 - val_accuracy: 0.2222\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.5922 - accuracy: 0.2961 - val_loss: 2.2209 - val_accuracy: 0.2222\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.5766 - accuracy: 0.3472 - val_loss: 2.5459 - val_accuracy: 0.0044\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.5577 - accuracy: 0.3661 - val_loss: 2.4227 - val_accuracy: 0.1111\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.5592 - accuracy: 0.3411 - val_loss: 2.4353 - val_accuracy: 0.1111\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.5430 - accuracy: 0.3811 - val_loss: 2.4997 - val_accuracy: 0.1111\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.5322 - accuracy: 0.3700 - val_loss: 2.5546 - val_accuracy: 0.1122\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.5338 - accuracy: 0.3844 - val_loss: 2.5537 - val_accuracy: 0.1056\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.5363 - accuracy: 0.4461 - val_loss: 2.5498 - val_accuracy: 0.1111\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.5247 - accuracy: 0.4161 - val_loss: 2.5858 - val_accuracy: 0.1111\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.5199 - accuracy: 0.4206 - val_loss: 2.5796 - val_accuracy: 0.1111\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.5018 - accuracy: 0.4800 - val_loss: 2.5217 - val_accuracy: 0.1111\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4906 - accuracy: 0.4767 - val_loss: 2.6737 - val_accuracy: 0.1083\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.4867 - accuracy: 0.4628 - val_loss: 2.5858 - val_accuracy: 0.1128\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.4732 - accuracy: 0.4700 - val_loss: 2.5883 - val_accuracy: 0.1111\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4721 - accuracy: 0.5711 - val_loss: 2.6148 - val_accuracy: 0.1111\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.4612 - accuracy: 0.4600 - val_loss: 3.0051 - val_accuracy: 0.1178\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.4648 - accuracy: 0.4861 - val_loss: 2.8889 - val_accuracy: 0.0261\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4584 - accuracy: 0.5778 - val_loss: 2.8523 - val_accuracy: 0.1072\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.5502 - accuracy: 0.4044 - val_loss: 4.9200 - val_accuracy: 0.1111\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.9274 - accuracy: 0.2328 - val_loss: 2.4526 - val_accuracy: 0.1111\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.5753 - accuracy: 0.3022 - val_loss: 2.3001 - val_accuracy: 0.2683\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4737 - accuracy: 0.4472 - val_loss: 2.7025 - val_accuracy: 0.1083\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.4528 - accuracy: 0.4872 - val_loss: 2.5577 - val_accuracy: 0.1672\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4308 - accuracy: 0.5522 - val_loss: 2.8980 - val_accuracy: 0.1111\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4435 - accuracy: 0.5361 - val_loss: 2.5647 - val_accuracy: 0.1544\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4322 - accuracy: 0.5106 - val_loss: 2.7948 - val_accuracy: 0.1111\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4064 - accuracy: 0.5917 - val_loss: 2.9236 - val_accuracy: 0.1111\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.4000 - accuracy: 0.5094 - val_loss: 2.7916 - val_accuracy: 0.1111\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.3891 - accuracy: 0.5594 - val_loss: 2.6271 - val_accuracy: 0.1406\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.3978 - accuracy: 0.5483 - val_loss: 2.7101 - val_accuracy: 0.1183\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.3864 - accuracy: 0.5244 - val_loss: 2.7230 - val_accuracy: 0.1211\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4065 - accuracy: 0.5344 - val_loss: 3.3383 - val_accuracy: 0.0250\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.3812 - accuracy: 0.5533 - val_loss: 2.5635 - val_accuracy: 0.2206\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.3687 - accuracy: 0.5378 - val_loss: 3.3513 - val_accuracy: 0.0656\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.3241 - accuracy: 0.5900 - val_loss: 2.7974 - val_accuracy: 0.1294\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.2953 - accuracy: 0.5756 - val_loss: 3.2333 - val_accuracy: 0.1111\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.3241 - accuracy: 0.6017 - val_loss: 2.9022 - val_accuracy: 0.1183\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.3084 - accuracy: 0.6017 - val_loss: 3.3512 - val_accuracy: 0.1111\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.2856 - accuracy: 0.5811 - val_loss: 3.3469 - val_accuracy: 0.1111\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.2810 - accuracy: 0.5694 - val_loss: 3.4888 - val_accuracy: 0.1111\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2591 - accuracy: 0.5633 - val_loss: 3.3164 - val_accuracy: 0.1111\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2706 - accuracy: 0.5772 - val_loss: 3.3071 - val_accuracy: 0.1111\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2455 - accuracy: 0.5994 - val_loss: 3.5539 - val_accuracy: 0.1111\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.2625 - accuracy: 0.6228 - val_loss: 3.3556 - val_accuracy: 0.1111\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2492 - accuracy: 0.5606 - val_loss: 4.0015 - val_accuracy: 0.1056\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2259 - accuracy: 0.6178 - val_loss: 3.6675 - val_accuracy: 0.1111\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2260 - accuracy: 0.6106 - val_loss: 3.9477 - val_accuracy: 0.1111\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.2169 - accuracy: 0.6339 - val_loss: 3.8991 - val_accuracy: 0.1111\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1994 - accuracy: 0.5744 - val_loss: 3.9070 - val_accuracy: 0.1111\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2292 - accuracy: 0.5889 - val_loss: 4.6105 - val_accuracy: 0.1356\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1888 - accuracy: 0.5517 - val_loss: 3.7087 - val_accuracy: 0.1111\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.2315 - accuracy: 0.5678 - val_loss: 5.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1907 - accuracy: 0.5839 - val_loss: 3.4656 - val_accuracy: 0.1133\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1739 - accuracy: 0.5939 - val_loss: 3.8651 - val_accuracy: 0.1111\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1669 - accuracy: 0.6311 - val_loss: 4.3079 - val_accuracy: 0.1111\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1594 - accuracy: 0.5633 - val_loss: 3.8877 - val_accuracy: 0.1111\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1727 - accuracy: 0.6378 - val_loss: 4.5385 - val_accuracy: 0.1111\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1493 - accuracy: 0.5917 - val_loss: 3.9943 - val_accuracy: 0.1111\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1425 - accuracy: 0.6417 - val_loss: 4.6776 - val_accuracy: 0.1111\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1549 - accuracy: 0.5839 - val_loss: 4.0663 - val_accuracy: 0.1111\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1306 - accuracy: 0.6394 - val_loss: 4.4397 - val_accuracy: 0.1111\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1766 - accuracy: 0.5528 - val_loss: 3.6228 - val_accuracy: 0.1661\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1501 - accuracy: 0.5906 - val_loss: 4.8230 - val_accuracy: 0.1111\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1245 - accuracy: 0.6383 - val_loss: 4.6718 - val_accuracy: 0.1111\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1310 - accuracy: 0.6111 - val_loss: 4.8464 - val_accuracy: 0.1111\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1099 - accuracy: 0.6372 - val_loss: 4.5730 - val_accuracy: 0.1111\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.1111 - accuracy: 0.5878 - val_loss: 4.9012 - val_accuracy: 0.1111\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.2120 - accuracy: 0.5244 - val_loss: 3.4938 - val_accuracy: 0.3194\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1414 - accuracy: 0.5672 - val_loss: 4.2822 - val_accuracy: 0.1111\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0919 - accuracy: 0.6444 - val_loss: 3.9042 - val_accuracy: 0.1528\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1162 - accuracy: 0.6022 - val_loss: 4.4914 - val_accuracy: 0.1111\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0945 - accuracy: 0.6317 - val_loss: 4.3845 - val_accuracy: 0.1111\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0871 - accuracy: 0.6394 - val_loss: 4.6825 - val_accuracy: 0.1111\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0888 - accuracy: 0.6378 - val_loss: 4.3700 - val_accuracy: 0.1111\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0840 - accuracy: 0.6139 - val_loss: 4.5506 - val_accuracy: 0.1111\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0871 - accuracy: 0.6178 - val_loss: 5.9108 - val_accuracy: 0.1111\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0923 - accuracy: 0.6400 - val_loss: 5.5705 - val_accuracy: 0.1111\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0528 - accuracy: 0.6300 - val_loss: 5.0665 - val_accuracy: 0.1111\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.0367 - accuracy: 0.6422 - val_loss: 5.7072 - val_accuracy: 0.1111\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.0849 - accuracy: 0.6156 - val_loss: 4.1842 - val_accuracy: 0.2100\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.1360 - accuracy: 0.5572 - val_loss: 3.2361 - val_accuracy: 0.1111\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.3076 - accuracy: 0.2028 - val_loss: 3.1813 - val_accuracy: 0.1111\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 2.3074 - accuracy: 0.1989 - val_loss: 3.0486 - val_accuracy: 0.1111\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.1570 - accuracy: 0.2283 - val_loss: 2.9476 - val_accuracy: 0.1111\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.1586 - accuracy: 0.2178 - val_loss: 2.8510 - val_accuracy: 0.1111\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.0868 - accuracy: 0.2172 - val_loss: 2.7792 - val_accuracy: 0.1111\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.0659 - accuracy: 0.2156 - val_loss: 2.7220 - val_accuracy: 0.1111\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.0162 - accuracy: 0.2194 - val_loss: 2.6768 - val_accuracy: 0.1111\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9902 - accuracy: 0.2183 - val_loss: 2.6391 - val_accuracy: 0.1111\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9707 - accuracy: 0.2172 - val_loss: 2.6114 - val_accuracy: 0.1111\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9581 - accuracy: 0.2167 - val_loss: 2.5881 - val_accuracy: 0.1111\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9397 - accuracy: 0.2172 - val_loss: 2.5695 - val_accuracy: 0.1111\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9278 - accuracy: 0.2167 - val_loss: 2.5563 - val_accuracy: 0.1111\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9235 - accuracy: 0.2167 - val_loss: 2.5442 - val_accuracy: 0.1111\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9193 - accuracy: 0.2161 - val_loss: 2.5344 - val_accuracy: 0.1111\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8955 - accuracy: 0.2189 - val_loss: 2.5262 - val_accuracy: 0.1111\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8935 - accuracy: 0.2161 - val_loss: 2.5207 - val_accuracy: 0.1111\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8985 - accuracy: 0.2172 - val_loss: 2.5156 - val_accuracy: 0.1111\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9048 - accuracy: 0.2156 - val_loss: 2.5101 - val_accuracy: 0.1111\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8788 - accuracy: 0.2167 - val_loss: 2.5072 - val_accuracy: 0.1111\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8732 - accuracy: 0.2167 - val_loss: 2.5043 - val_accuracy: 0.1111\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8653 - accuracy: 0.2172 - val_loss: 2.5025 - val_accuracy: 0.1111\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8881 - accuracy: 0.2128 - val_loss: 2.5000 - val_accuracy: 0.1111\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8288 - accuracy: 0.2350 - val_loss: 4.8684 - val_accuracy: 0.1111\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.7413 - accuracy: 0.2694 - val_loss: 2.5112 - val_accuracy: 0.1111\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8966 - accuracy: 0.2050 - val_loss: 2.5028 - val_accuracy: 0.1111\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8850 - accuracy: 0.2178 - val_loss: 2.4981 - val_accuracy: 0.1111\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8938 - accuracy: 0.2161 - val_loss: 2.4930 - val_accuracy: 0.1111\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.9037 - accuracy: 0.2139 - val_loss: 2.4898 - val_accuracy: 0.1111\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8897 - accuracy: 0.2161 - val_loss: 2.4870 - val_accuracy: 0.1111\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.8920 - accuracy: 0.2156 - val_loss: 2.4850 - val_accuracy: 0.1111\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8882 - accuracy: 0.2161 - val_loss: 2.4834 - val_accuracy: 0.1111\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8973 - accuracy: 0.2067 - val_loss: 2.4821 - val_accuracy: 0.1111\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8873 - accuracy: 0.2078 - val_loss: 2.4804 - val_accuracy: 0.1111\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8746 - accuracy: 0.2083 - val_loss: 2.4797 - val_accuracy: 0.1111\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8773 - accuracy: 0.2178 - val_loss: 2.4792 - val_accuracy: 0.1111\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8820 - accuracy: 0.2167 - val_loss: 2.4790 - val_accuracy: 0.1111\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8908 - accuracy: 0.2100 - val_loss: 2.4775 - val_accuracy: 0.1111\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8867 - accuracy: 0.2039 - val_loss: 2.4763 - val_accuracy: 0.1111\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.9021 - accuracy: 0.2061 - val_loss: 2.4751 - val_accuracy: 0.1111\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8864 - accuracy: 0.2083 - val_loss: 2.4738 - val_accuracy: 0.1111\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.9049 - accuracy: 0.2089 - val_loss: 2.4721 - val_accuracy: 0.1111\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8831 - accuracy: 0.2167 - val_loss: 2.4712 - val_accuracy: 0.1111\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8831 - accuracy: 0.2150 - val_loss: 2.4706 - val_accuracy: 0.1111\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8799 - accuracy: 0.2117 - val_loss: 2.4703 - val_accuracy: 0.1111\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8860 - accuracy: 0.2161 - val_loss: 2.4692 - val_accuracy: 0.1111\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8675 - accuracy: 0.2150 - val_loss: 2.4690 - val_accuracy: 0.1111\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8737 - accuracy: 0.2100 - val_loss: 2.4691 - val_accuracy: 0.1111\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8613 - accuracy: 0.2206 - val_loss: 2.4693 - val_accuracy: 0.1111\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8829 - accuracy: 0.2094 - val_loss: 2.4691 - val_accuracy: 0.1111\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8984 - accuracy: 0.2006 - val_loss: 2.4677 - val_accuracy: 0.1111\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 1.8859 - accuracy: 0.2133 - val_loss: 2.4672 - val_accuracy: 0.1083\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8829 - accuracy: 0.2117 - val_loss: 2.4662 - val_accuracy: 0.1150\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8798 - accuracy: 0.2117 - val_loss: 2.4658 - val_accuracy: 0.1067\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1.9016 - accuracy: 0.1994 - val_loss: 2.4646 - val_accuracy: 0.1111\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8984 - accuracy: 0.2039 - val_loss: 2.4625 - val_accuracy: 0.1111\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8678 - accuracy: 0.2117 - val_loss: 2.4619 - val_accuracy: 0.1111\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8829 - accuracy: 0.2067 - val_loss: 2.4616 - val_accuracy: 0.1111\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8890 - accuracy: 0.2039 - val_loss: 2.4604 - val_accuracy: 0.1111\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8767 - accuracy: 0.2133 - val_loss: 2.4598 - val_accuracy: 0.1111\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8676 - accuracy: 0.2194 - val_loss: 2.4598 - val_accuracy: 0.1111\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8798 - accuracy: 0.2061 - val_loss: 2.4595 - val_accuracy: 0.1111\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.8768 - accuracy: 0.2178 - val_loss: 2.4594 - val_accuracy: 0.1111\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8736 - accuracy: 0.2067 - val_loss: 2.4593 - val_accuracy: 0.1072\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8918 - accuracy: 0.2128 - val_loss: 2.4581 - val_accuracy: 0.1111\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8858 - accuracy: 0.2089 - val_loss: 2.4570 - val_accuracy: 0.1111\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8735 - accuracy: 0.2183 - val_loss: 2.4568 - val_accuracy: 0.1111\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8736 - accuracy: 0.2183 - val_loss: 2.4568 - val_accuracy: 0.1111\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8889 - accuracy: 0.2028 - val_loss: 2.4560 - val_accuracy: 0.1111\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8858 - accuracy: 0.2083 - val_loss: 2.4550 - val_accuracy: 0.1106\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.8827 - accuracy: 0.2050 - val_loss: 2.4545 - val_accuracy: 0.1111\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8827 - accuracy: 0.2072 - val_loss: 2.4540 - val_accuracy: 0.1422\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8826 - accuracy: 0.2083 - val_loss: 2.4534 - val_accuracy: 0.1111\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8616 - accuracy: 0.2100 - val_loss: 2.4540 - val_accuracy: 0.1111\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 1.8947 - accuracy: 0.2178 - val_loss: 2.4536 - val_accuracy: 0.1111\n"
     ]
    }
   ],
   "source": [
    "history = adversary.fit(adv_X, adv_y_one_hot, batch_size=80, epochs=200, validation_data=(adv_X_test, adv_y_test_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8388ef1087ea205",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64a8f2fa7819614b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T13:50:01.248044175Z",
     "start_time": "2023-12-04T13:50:00.207227940Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12446865, 0.12396079, 0.00446714, ..., 0.12463421, 0.12420047,\n",
       "        0.12487885],\n",
       "       [0.12446865, 0.12396079, 0.00446714, ..., 0.12463421, 0.12420047,\n",
       "        0.12487885],\n",
       "       [0.12446865, 0.12396079, 0.00446714, ..., 0.12463421, 0.12420047,\n",
       "        0.12487885],\n",
       "       ...,\n",
       "       [0.12446865, 0.12396079, 0.00446714, ..., 0.12463421, 0.12420047,\n",
       "        0.12487885],\n",
       "       [0.12446865, 0.12396079, 0.00446714, ..., 0.12463421, 0.12420047,\n",
       "        0.12487885],\n",
       "       [0.12446865, 0.12396079, 0.00446714, ..., 0.12463421, 0.12420047,\n",
       "        0.12487885]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversary.predict(adv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57a281ccdfca4382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:33:46.092700833Z",
     "start_time": "2023-11-02T16:33:46.071360597Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.7\n",
       "1      0.8\n",
       "2      0.3\n",
       "3      0.4\n",
       "4      0.5\n",
       "      ... \n",
       "355    0.6\n",
       "356    0.7\n",
       "357    0.2\n",
       "358    0.6\n",
       "359    0.1\n",
       "Name: y, Length: 360, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb69675f6aa542fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:34:36.130626316Z",
     "start_time": "2023-11-02T16:34:35.911004092Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10118263214826584"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversary.evaluate(adv_X_test, adv_y_test)#, adv_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b46ef5956a55a615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:53:33.952649657Z",
     "start_time": "2023-11-02T09:53:33.941640016Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.9\n",
       "1      0.8\n",
       "2      0.4\n",
       "3      0.2\n",
       "4      0.1\n",
       "      ... \n",
       "445    0.6\n",
       "446    0.2\n",
       "447    0.8\n",
       "448    0.5\n",
       "449    0.1\n",
       "Name: y, Length: 450, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f74456ef02429",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Next steps\n",
    "* Use adversary during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "891ebfee697bab39",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-08T11:01:55.769151441Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.027966356472107767"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(adv_X, adv_y)\n",
    "gb.score(adv_X_test, adv_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7861d95cdcba85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### (Data set analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd121bbeca4944",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ydata_profiling\n",
    "\n",
    "ydata_profiling.ProfileReport(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e83d6cc0260faf0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RANDOM DS\n",
    "random_dict = {}\n",
    "for attr in ds.X_train:\n",
    "    print(f'{round(X_train_pr[attr].min(),2)} {round(X_train_pr[attr].max(),2)}')\n",
    "    random_attr = np.random.rand(random_length)*(X_train_pr[attr].max()+abs(X_train_pr[attr].min()))-abs(X_train_pr[attr].min())\n",
    "    random_dict[attr] = random_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d705447fbbf00",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_ds = pd.DataFrame(random_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pia1",
   "language": "python",
   "name": "pia1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
